 
# OLTP X OLAP

| Crit√©rio            | OLTP (Transacional)                                  | OLAP (Anal√≠tico)                                      |
|---------------------|------------------------------------------------------|-------------------------------------------------------|
| **Foco**            | Registro de transa√ß√µes individuais e atuais          | An√°lise de tend√™ncias, padr√µes e hist√≥rico            |
| **Volume de Dados** | Recupera apenas alguns registros por vez             | Processa milhares ou milh√µes de registros             |
| **Frequ√™ncia**      | Milhares de consultas por hora                       | Execu√ß√£o pouco frequente por grupos menores           |
| **N√≠vel de Detalhe**| Dados at√¥micos (pedidos, transa√ß√µes)                 | Dados **agregados** e consolidados                    |
| **Velocidade**      | Respostas em milissegundos ou poucos segundos        | Pode levar v√°rios segundos devido √† complexidade      |
‚Ä¢ **Leitura em OLTP:** As opera√ß√µes de leitura s√£o otimizadas para localizar **registros espec√≠ficos** de forma r√°pida, geralmente para suportar fun√ß√µes operacionais (como verificar o status de um pedido).

‚Ä¢ **Leitura em OLAP:** Exige a leitura de **grandes blocos de dados** para realizar varreduras extensas em tabelas de fatos e dimens√µes. Para otimizar esse processo, costuma-se usar formatos **colunares** (como Parquet) e t√©cnicas de **particionamento**, que reduzem a quantidade de dados lidos (pruning) durante a consulta.

‚Ä¢ **Agrega√ß√£o:** No OLTP, as agrega√ß√µes s√£o raras e evitadas para n√£o comprometer a performance transacional. J√° no OLAP, a **agrega√ß√£o √© o objetivo principal**, permitindo agrupar registros por per√≠odos, regi√µes ou categorias para extrair _insights_ √∫teis.

**Contexto Arquitetural**

Os sistemas OLTP funcionam como as **fontes de origem** (Source of Record). Para que a an√°lise ocorra sem sobrecarregar a opera√ß√£o, os dados s√£o movidos atrav√©s de processos de **ETL (Extra√ß√£o, Transforma√ß√£o e Carregamento)** para sistemas OLAP, como os **Data Warehouses**. Nestes ambientes, utiliza-se frequentemente o design de **esquema em estrela** (_star schema_), onde tabelas de fatos armazenam m√©tricas num√©ricas e tabelas de dimens√µes armazenam dados mestres, facilitando as jun√ß√µes (_joins_) e agrega√ß√µes anal√≠ticas.

A **Modelagem Anal√≠tica Dimensional** √© uma t√©cnica de design de banco de dados otimizada para a recupera√ß√£o de dados e an√°lise em larga escala, sendo a base dos **Data Warehouses** e **Data Marts**. Diferente do modelo relacional tradicional (OLTP), ela organiza os dados de forma a facilitar o consumo por ferramentas de Business Intelligence (BI) e usu√°rios de neg√≥cio.

Abaixo, detalho os conceitos fundamentais, boas pr√°ticas e justificativas de uso:

**1. Componentes da Modelagem Dimensional**

‚Ä¢ **Tabelas de Fatos:** S√£o utilizadas para armazenar n√∫meros ou **m√©tricas** relacionadas a transa√ß√µes ou eventos de neg√≥cio, como o pre√ßo de um produto ou a quantidade vendida.

‚Ä¢ **Tabelas de Dimens√µes:** Cont√™m os dados mestres e cadastrais que descrevem o contexto do fato, como informa√ß√µes de clientes, produtos ou tempo.

‚Ä¢ **Granularidade:** Refere-se ao n√≠vel de detalhe armazenado em uma tabela de fatos (ex: uma linha por venda por dia ou uma linha por item por minuto).

‚Ä¢ **Chaves Substitutas (Surrogate Keys):** S√£o chaves artificiais criadas para identificar unicamente cada linha em uma dimens√£o, garantindo estabilidade e performance nas jun√ß√µes, independentemente das chaves dos sistemas de origem.

**2. Boas Pr√°ticas e Organiza√ß√£o**

‚Ä¢ **Conformidade de Dimens√µes:** Dimens√µes devem ser padronizadas para que possam ser compartilhadas entre diferentes fatos em toda a organiza√ß√£o, garantindo que "cliente" signifique a mesma coisa em todos os departamentos.

‚Ä¢ **SCD (Slowly Changing Dimensions):** T√©cnica aplicada quando os atributos de uma dimens√£o mudam ao longo do tempo (ex: um cliente que muda de endere√ßo), permitindo rastrear o hist√≥rico dessas altera√ß√µes.

‚Ä¢ **M√©tricas bem definidas:** Devem ser claras e consistentes para evitar interpreta√ß√µes divergentes entre as √°reas de neg√≥cio.

‚Ä¢ **Data Marts:** S√£o subconjuntos do Data Warehouse focados em √°reas espec√≠ficas (Marketing, RH, Vendas). Eles oferecem **maior velocidade de acesso**, menor depend√™ncia da TI e custos de implementa√ß√£o reduzidos.

**3. Justificativa do Star Schema (Esquema em Estrela)**

O **Star Schema** √© o design mais comum em Data Warehousing, onde uma tabela de fatos central √© conectada a v√°rias tabelas de dimens√µes.

**Vantagens para Leitura e BI:**

‚Ä¢ **Simplifica√ß√£o de Joins:** As jun√ß√µes s√£o feitas diretamente entre a fato e as dimens√µes, evitando cadeias complexas de relacionamento.

‚Ä¢ **Performance:** √â otimizado para consultas **OLAP**, que buscam e processam milhares ou milh√µes de registros para identificar tend√™ncias e padr√µes.

‚Ä¢ **Clareza para o Usu√°rio:** A estrutura √© intuitiva, facilitando a navega√ß√£o de usu√°rios de neg√≥cio que utilizam ferramentas de self-service BI.

**4. Impactos na Performance e Clareza**

‚Ä¢ **Granularidade:** Uma granularidade muito alta (muito detalhe) aumenta o volume de dados e pode impactar a performance, mas permite an√°lises mais profundas. Uma granularidade baixa (dados agregados) √© mais r√°pida, mas limita a capacidade de detalhamento (_drill-down_).

‚Ä¢ **Joins:** Em modelos mal projetados, o excesso de jun√ß√µes complexas degrada a performance das consultas. No Star Schema, a estrutura denormalizada das dimens√µes reduz a necessidade de m√∫ltiplos joins, tornando a execu√ß√£o das queries mais eficiente.

**Common Table Expressions (CTEs)**

As CTEs (definidas pela cl√°usula `WITH`) s√£o conjuntos de resultados tempor√°rios que existem apenas durante a execu√ß√£o de uma √∫nica query. Elas funcionam como "tabelas auxiliares" que organizam o c√≥digo.

**Por que s√£o prefer√≠veis em l√≥gicas complexas?**

‚Ä¢ **Legibilidade:** Permitem decompor uma l√≥gica densa em blocos l√≥gicos menores e nomeados, tornando o c√≥digo mais f√°cil de ler e manter.

‚Ä¢ **Reuso:** Voc√™ pode referenciar a mesma CTE m√∫ltiplas vezes dentro da query principal.

‚Ä¢ **Depura√ß√£o:** Facilita testar partes isoladas da transforma√ß√£o antes de chegar ao resultado final

O processo de **ETL/ELT orientado ao consumo** foca em transformar dados brutos em ativos estrat√©gicos prontos para uso por analistas e cientistas de dados. Enquanto o **ETL** (Extra√ß√£o, Transforma√ß√£o e Carregamento) transforma os dados antes do destino, o **ELT** (Extra√ß√£o, Carregamento e Transforma√ß√£o) carrega os dados brutos e utiliza o poder de processamento do destino (como Cloud Data Warehouses) para a transforma√ß√£o.

**1. Crit√©rios de Escolha: ETL vs. ELT**

A decis√£o entre os modelos depende do equil√≠brio entre quatro pilares principais:

‚Ä¢ **Governan√ßa:** O ETL √© preferido para **dados sens√≠veis** (como LGPD), permitindo transforma√ß√µes antes do armazenamento. J√° o ELT favorece a **linhagem e auditoria**, mantendo os dados originais dispon√≠veis na Raw Zone para reprocessamento.

‚Ä¢ **Lat√™ncia:** O ELT costuma ser mais r√°pido no carregamento inicial, eliminando a espera pela pr√©-transforma√ß√£o.

‚Ä¢ **Custo:** O ELT aproveita a **escalabilidade da nuvem** e modelos de "pague pelo uso", enquanto o ETL pode exigir infraestrutura dedicada e cara.

‚Ä¢ **Acoplamento:** O ELT tem maior acoplamento com o mecanismo de consulta (ex: BigQuery, Snowflake), pois as transforma√ß√µes ocorrem dentro dele via SQL.




--------------------------------------------------------------------------------

**2. Fluxos T√≠picos em Camadas**

A organiza√ß√£o por zonas evita que o reposit√≥rio se torne um "p√¢ntano de dados" (Data Swamp). O fluxo padr√£o segue estas etapas:

1. **Ingest√£o (Transient/Raw Zone):** Dados brutos chegam de fontes como APIs ou Logs e s√£o armazenados sem modifica√ß√£o para garantir fidelidade.

2. **Padroniza√ß√£o e Valida√ß√£o (Trusted Zone):** Os dados s√£o limpos (remo√ß√£o de nulos e duplicatas) e padronizados (formatos de data e moeda). Aqui, os dados tornam-se a **Source of Truth** (Fonte da Verdade).

3. **Publica√ß√£o e Exposi√ß√£o (Refined Zone):** Dados enriquecidos, agregados e modelados (como em **Star Schema**) s√£o disponibilizados para ferramentas de BI e dashboards.

--------------------------------------------------------------------------------

**3. Estrat√©gias de Carga: Completa vs. Incremental**

A escolha da carga afeta a efici√™ncia do pipeline e a capacidade de recupera√ß√£o:

‚Ä¢ **Carga Completa (Full Load):** Todo o conjunto de dados √© substitu√≠do. √â mais simples, por√©m cara e lenta para grandes volumes.

‚Ä¢ **Carga Incremental:** Apenas dados novos ou alterados s√£o processados.

¬†¬†¬†¬†‚ó¶ **Marca√ß√£o de Progresso:** Utiliza chaves como `data_atualizacao` ou `id` para identificar onde a carga anterior parou.
¬†¬†¬†¬†

¬†¬†¬†¬†‚ó¶ **Idempot√™ncia:** √â a garantia de que reexecutar o pipeline para o mesmo per√≠odo n√£o gerar√° dados duplicados ou inconsistentes, algo vital para o **reprocessamento isolado**.

--------------------------------------------------------------------------------

**4. Pontos de Controle antes do Consumo**

Para garantir a confiabilidade, o engenheiro de analytics deve implementar travas de seguran√ßa (Data Quality):

‚Ä¢ **Valida√ß√£o de Schema:** Garantir que as colunas e tipos de dados n√£o mudaram inesperadamente.

‚Ä¢ **Integridade e Unicidade:** Verificar se campos obrigat√≥rios est√£o preenchidos e se h√° registros duplicados (Taxa de Unicidade).

‚Ä¢ **Fail Fast:** Implementar fluxos de **quarentena** que bloqueiam a publica√ß√£o na Refined Zone se os indicadores de qualidade n√£o forem atingidos.

‚Ä¢ **Observabilidade:** Gerar evid√™ncias, logs estruturados e alertas caso o pipeline falhe ou a lat√™ncia exceda o SLA acordado

# Orquestra√ß√£o de Pipelines Anal√≠ticos

A **orquestra√ß√£o de pipelines anal√≠ticos** √© o processo de automatizar e organizar o fluxo entre tarefas, coordenando todas as etapas de desenvolvimento, processamento e entrega de dados. Ela garante que os dados se movam de forma fluida e confi√°vel entre as camadas **Raw**, **Trusted** e **Refined**, gerenciando a complexidade das depend√™ncias e falhas.

Abaixo, detalho os **pilares t√©cnicos** e as **estrat√©gias de prepara√ß√£o para orquestra√ß√£o**.

---

## 1. Pilares T√©cnicos da Orquestra√ß√£o

Para garantir a robustez de um pipeline, o orquestrador deve gerenciar:

- **Depend√™ncias**  
  Define a ordem l√≥gica de execu√ß√£o  
  _Exemplo: a tabela de Dimens√£o deve ser atualizada antes da tabela de Fatos._

- **Retries e Backoff**  
  Mecanismos de tentativas autom√°ticas ap√≥s uma falha, muitas vezes com intervalos crescentes (*backoff*) para evitar sobrecarga no sistema de origem.

- **Paralelismo**  
  Capacidade de executar tarefas independentes simultaneamente, otimizando o tempo total de processamento.

- **Timeouts**  
  Defini√ß√£o de limites de tempo para a execu√ß√£o de uma tarefa, evitando que processos travados consumam recursos indefinidamente.

---

## 2. Orquestra√ß√£o Nativa vs. Fluxos Multi-servi√ßo

A escolha da ferramenta depende da complexidade do ambiente:

- **Orquestra√ß√£o Nativa**  
  Geralmente embutida em ferramentas espec√≠ficas de ETL  
  _Exemplos: agendamento do AWS Glue ou Oozie no Hadoop._  
  √â ideal para pipelines simples dentro do mesmo ecossistema.

- **Fluxos Multi-servi√ßo**  
  Utilizam orquestradores dedicados, como **Apache Airflow** ou **AWS Step Functions**, para gerenciar fluxos que envolvem m√∫ltiplas tecnologias e l√≥gica condicional complexa.  
  _Exemplo: um fluxo que inicia com um crawler, executa um job Spark e termina atualizando um dashboard no QuickSight._

---

## 3. Reprocessamento Isolado e Idempot√™ncia

Uma das compet√™ncias mais cr√≠ticas na engenharia de analytics √© o planejamento de reprocessamentos:

- **Evitar o Rerun Completo**  
  O pipeline deve ser desenhado para permitir o reprocessamento apenas de etapas espec√≠ficas que falharam ou que precisam de corre√ß√£o.

- **Idempot√™ncia**  
  Garantia de que reexecutar uma etapa para o mesmo per√≠odo de tempo produzir√° o mesmo resultado, sem duplicar dados ou gerar inconsist√™ncias.

- **Marcadores de Progresso**  
  Uso de *bookmarks* ou chaves de controle para identificar exatamente onde o processamento parou, permitindo cargas incrementais eficientes.

---

## 4. Integra√ß√µes e Notifica√ß√µes

Um orquestrador moderno atua como o **‚Äúc√©rebro‚Äù do ecossistema**:

- **Conectividade**  
  Integra-se nativamente com motores de processamento (Spark, Hive), bancos de dados (Redshift) e ferramentas de ingest√£o (Kafka).

- **Observabilidade e Alertas**  
  Gera evid√™ncias e notifica√ß√µes autom√°ticas em caso de erro ou atraso no **SLA (Service Level Agreement)**, garantindo transpar√™ncia para as √°reas usu√°rias.

---

## Resumo de Prepara√ß√£o

| Conceito            | Foco para a Pr√°tica                                                                 |
|---------------------|-------------------------------------------------------------------------------------|
| L√≥gica Condicional  | Usar fluxos multi-servi√ßo quando a pr√≥xima etapa depende do resultado da anterior. |
| Gest√£o de Falhas    | Configurar retries adequados para lidar com instabilidades tempor√°rias de rede/API.|
| Pontos de Controle  | Validar a qualidade do dado antes de permitir que o orquestrador publique para consumo. |
## 6. Processamento Distribu√≠do (Vis√£o Aplicada)

O processamento distribu√≠do, liderado por frameworks como o **Apache Spark**, permite lidar com Big Data atrav√©s do processamento em mem√≥ria e execu√ß√£o paralela em clusters.

### Conceitos Essenciais

- **Transforma√ß√µes vs. A√ß√µes**  
  Transforma√ß√µes (ex: `map`, `filter`) criam novos RDDs e utilizam **avalia√ß√£o pregui√ßosa (lazy evaluation)**, ou seja, s√≥ s√£o executadas quando uma A√ß√£o (ex: `count`, `collect`) √© chamada.

- **Plano L√≥gico e Plano F√≠sico**  
  O **Driver Program** coordena a execu√ß√£o e converte o c√≥digo em um **DAG (Grafo Ac√≠clico Direcionado)** para otimizar o plano de execu√ß√£o antes de envi√°-lo aos **Workers**.

### Pr√°ticas de Otimiza√ß√£o

- **Pushdown**  
  Aplicar filtros o mais cedo poss√≠vel para reduzir o volume de dados processados.

- **Particionamento**  
  Dividir os dados em partes menores para melhorar o desempenho e a escalabilidade.

- **Gargalos Comuns**  
  O **Shuffle** (redistribui√ß√£o de dados entre n√≥s) √© o gargalo mais caro devido ao uso intensivo de rede e disco.  
  Deve-se evitar opera√ß√µes como `groupByKey` em favor de `reduceByKey`.

---

## 7. Qualidade de Dados (Data Quality)

A qualidade √© a base para decis√µes assertivas; dados ruins podem custar de **15% a 25% da receita anual** de uma empresa.

### Tipos de Regras (6 Dimens√µes)

- **Precis√£o**: dados corretos  
- **Integridade**: aus√™ncia de campos faltantes  
- **Consist√™ncia**: uniformidade entre sistemas  
- **Atualidade**: dados recentes  
- **Unicidade**: aus√™ncia de duplicatas  
- **Conformidade**: ader√™ncia a padr√µes e regulamentos

### Integra√ß√£o e Fluxos

- Validar os dados **antes** de public√°-los na camada de consumo (*fail-fast*).
- Utilizar **fluxos de quarentena** para isolar dados reprovados.

### M√©tricas de Qualidade

- Taxa de Completude  
- Taxa de Acuracidade  
- Taxa de Duplica√ß√£o  

Essas m√©tricas ajudam a monitorar continuamente a sa√∫de do **Data Lake**.

---

## 8. Governan√ßa, Cat√°logo e Seguran√ßa

A governan√ßa transforma dados brutos em **ativos estrat√©gicos** por meio de processos e padr√µes bem definidos.

### Metadados Centralizados

- Ferramentas como **AWS Glue Catalog** ou **Apache Atlas** permitem catalogar tabelas, tipos e parti√ß√µes.
- Desacoplam a camada f√≠sica da l√≥gica de consumo.

### Controles de Acesso

- Uso de **IAM Roles** para conceder acesso granular (por banco ou tabela) e tempor√°rio.
- Elimina a necessidade de credenciais est√°ticas.

### Boas Pr√°ticas

- Padroniza√ß√£o de nomenclatura.
- Documenta√ß√£o clara, como **Dicion√°rio de Dados**, para evitar silos de informa√ß√£o.

---

## 9. Observabilidade e Opera√ß√£o

Observabilidade √© a capacidade de entender o estado interno de um sistema atrav√©s de suas sa√≠das.

### Os 3 Pilares da Observabilidade

1. **Logs**  
   Registros cronol√≥gicos de eventos para an√°lise e debug.

2. **M√©tricas**  
   Indicadores num√©ricos (lat√™ncia, erros, throughput) usados em dashboards e alertas.

3. **Tracing**  
   Rastreia o caminho de uma requisi√ß√£o entre m√∫ltiplos servi√ßos.

### Opera√ß√£o

- Uso de **IDs de correla√ß√£o** para rastrear execu√ß√µes ponta a ponta.
- Realiza√ß√£o de **post-mortems objetivos** ap√≥s incidentes para prevenir recorr√™ncias.

---

## 10. FinOps Aplicado a Analytics

O foco de **FinOps** √© reduzir gastos desnecess√°rios sem comprometer a performance.

### Estrat√©gias Principais

- **Redu√ß√£o de Leitura**  
  Uso estrat√©gico de particionamento e *partition pruning* reduz o volume de dados escaneados, impactando diretamente os custos de ferramentas como **Athena** ou **Redshift Spectrum**.

- **Gest√£o de Arquivos**  
  Evitar *small files* por meio de **compacta√ß√£o em batch**, otimizando I/O e custos de processamento.

- **Gest√£o de Recursos**  
  Dimensionar corretamente clusters (inst√¢ncias *spot* vs. *reservadas*) e desligar cargas ociosas.

---

## 11. Colabora√ß√£o e Versionamento

A engenharia de dados moderna adota pr√°ticas consolidadas de desenvolvimento de software.

### Boas Pr√°ticas

- **Fluxos com Git**  
  Todo c√≥digo de pipeline, modelagem e infraestrutura deve ser versionado.

- **Revis√£o de C√≥digo (Pull Requests)**  
  Melhora a qualidade, reduz regress√µes e dissemina conhecimento entre o time.

- **Valida√ß√µes Automatizadas**  
  Integra√ß√£o de testes de *lint* e checagens autom√°ticas de schema em pipelines de **CI/CD**.

---

## 12. Exerc√≠cios Pr√°ticos Recomendados

Para consolidar os conhecimentos apresentados, recomenda-se:

1. **Modelagem**  
   Criar um **Star Schema** para um dom√≠nio de vendas, definindo granularidade e chaves substitutas.

2. **SQL**  
   Escrever queries com **CTEs** e analisar o plano de execu√ß√£o para identificar *scans* desnecess√°rios.

3. **Data Quality**  
   Implementar valida√ß√µes de `not_null` e `unique` em um pipeline, gerando alertas em caso de falha.

4. **Orquestra√ß√£o**  
   Configurar um fluxo com **retries** e depend√™ncias entre camadas  
   *(Raw ‚Üí Trusted ‚Üí Refined)*.

## Star Schema vs. Snowflake Schema

**Star Schema** e **Snowflake Schema** s√£o **t√©cnicas de modelagem de dados para Data Warehouses**, tendo como principal diferen√ßa o n√≠vel de **normaliza√ß√£o**.

- O **Star Schema** utiliza **dimens√µes desnormalizadas**, priorizando **performance de consulta** e **simplicidade para an√°lise**.
- O **Snowflake Schema** utiliza **dimens√µes normalizadas**, reduzindo **redund√¢ncia de dados** e aumentando a **integridade**.

De forma geral, o **Star Schema** √© mais indicado para ferramentas de BI como **Power BI**, enquanto o **Snowflake Schema** se adapta melhor a **dados complexos e hier√°rquicos**.

---

## Principais Diferen√ßas

### Estrutura
- **Star Schema:**  
  Possui uma **tabela fato central** conectada diretamente √†s **tabelas de dimens√£o**.
- **Snowflake Schema:**  
  As dimens√µes s√£o **normalizadas** em m√∫ltiplas **sub-dimens√µes relacionadas**.

### Performance
- **Star Schema:**  
  Oferece **melhor desempenho** em consultas devido ao menor n√∫mero de *joins*.
- **Snowflake Schema:**  
  Pode apresentar **consultas mais lentas**, pois exige mais *joins* para recuperar os dados.

### Armazenamento
- **Star Schema:**  
  Consome **mais espa√ßo**, devido √† redund√¢ncia causada pela desnormaliza√ß√£o.
- **Snowflake Schema:**  
  √â **mais eficiente em armazenamento**, j√° que a normaliza√ß√£o reduz a duplica√ß√£o de dados.

### Complexidade
- **Star Schema:**  
  Mais **simples de projetar, entender e consultar**.
- **Snowflake Schema:**  
  Mais **complexo de manter**, por√©m **mais f√°cil de atualizar** quando h√° mudan√ßas nas dimens√µes.

---

## Quando Usar Cada Um

### ‚≠ê Star Schema
Utilize quando:
- O foco for **dashboards de BI**
- Houver necessidade de **consultas r√°pidas e ad-hoc**
- **Simplicidade e performance** forem prioridades

### ‚ùÑÔ∏è Snowflake Schema
Utilize quando:
- **Integridade dos dados** for cr√≠tica
- O **espa√ßo de armazenamento** for uma restri√ß√£o
- Os dados possu√≠rem **estruturas complexas e hier√°rquicas**

## Data Mesh 

- **Dados como produto** usar o mesmos princ√≠pios de engenharia de software
-  **Governan√ßa federada** uma √°rea central como respons√°vel pelos metadados 
-  **Dom√≠nio** cada √°rea de neg√≥cio √© respons√°vel 
- **Self Service** 
- Desafios: Dificuldade em garantir a qualidade de dados devido √† descentraliza√ß√£o
- Dados como produto: Os dados devem ser gerenciados e entregue com a mesma aten√ß√£o de engenharia de software.
- Vantagens: Melhoria na escalabilidade e agilidade, permitindo que as equipes se adaptem rapidamente as mudan√ßas de requisitos. 
- Cada dom√≠nio √© respons√°vel elos seus pr√≥prios dados, promovendo autonomia e propriedade
-

> **No Hadoop, o Master coordena e os Slaves executam ‚Äî tanto no storage quanto no processamento.**
> A arquitetura master/slave do Hadoop, essencial para big data, utiliza um n√≥ mestre (Master) para gerenciar metadados e coordenar tarefas, enquanto m√∫ltiplos n√≥s escravos (Slaves/Workers) armazenam dados (HDFS) e processam computa√ß√µes (MapReduce/YARN) em hardware comum

| Hadoop On-Prem | AWS                 |
| -------------- | ------------------- |
| NameNode       | S3 (gerenciado)     |
| DataNode       | S3                  |
| YARN           | Glue / EMR / Athena |
| Master/Slave   | Desacoplado         |

**AWS Glue Job Bookmark** √© um recurso da ferramenta AWS Glue projetado para rastrear o estado de execu√ß√£o de um job de ETL (Extra√ß√£o, Transforma√ß√£o e Carregamento). Ele funciona como um mecanismo de persist√™ncia que mant√©m a **marca√ß√£o de progresso** entre as execu√ß√µes de um pipeline.

Abaixo, detalho o funcionamento e a import√¢ncia desse recurso com base nos conceitos de engenharia presentes nas fontes:

**1. Suporte a Cargas Incrementais**

A principal fun√ß√£o do Job Bookmark √© facilitar a implementa√ß√£o de **cargas incrementais**. Em vez de processar toda a massa de dados em cada execu√ß√£o (o que seria uma carga completa), o Glue utiliza o bookmark para identificar apenas os novos dados que chegaram desde a √∫ltima execu√ß√£o bem-sucedida.

**2. Marca√ß√£o de Progresso e Estado**

O recurso atua registrando metadados sobre os objetos ou registros j√° processados. Isso √© essencial para:

‚Ä¢ **Evitar Duplicidade:** Garante que o mesmo dado n√£o seja processado e carregado novamente, mantendo a integridade na camada de destino.

‚Ä¢ **Idempot√™ncia:** Permite que o pipeline seja reexecutado de forma segura, garantindo que o resultado final seja consistente mesmo ap√≥s falhas parciais.

**3. Efici√™ncia Operacional e Reprocessamento**

O uso de bookmarks permite o planejamento de **reprocessamentos isolados**. Se houver uma falha em uma etapa espec√≠fica do pipeline, o engenheiro pode utilizar o estado salvo para retomar o trabalho sem a necessidade de um "rerun" completo de todo o hist√≥rico de dados, o que otimiza o tempo e reduz o esfor√ßo computacional.

Lidar com o problema de **small files** (arquivos pequenos) √© uma pr√°tica essencial de **FinOps** e processamento distribu√≠do, pois o excesso de fragmenta√ß√£o sobrecarrega a gest√£o de metadados e degrada o desempenho de motores de consulta como Spark e Athena.

Abaixo est√£o as estrat√©gias baseadas nas fontes para mitigar esse gargalo:

**1. Compacta√ß√£o (Compaction)**

A t√©cnica de compacta√ß√£o consiste em consolidar diversos arquivos min√∫sculos em arquivos maiores e mais eficientes para o sistema de arquivos.

‚Ä¢ **AWS S3DistCp:** No ecossistema AWS, a ferramenta **S3DistCp** √© especificamente recomendada para mover e agrupar grandes volumes de arquivos pequenos entre buckets S3 ou para o HDFS, reduzindo a sobrecarga de leitura.

‚Ä¢ **Merge em Jobs:** Durante os processos de ETL/ELT, √© recomendada a inclus√£o de etapas de reprocessamento que fa√ßam o "merge" desses arquivos antes de public√°-los em camadas de consumo, como a **Refined Zone**.

**2. Estrat√©gia de Particionamento e Pruning**

O particionamento incorreto √© uma das causas prim√°rias de "small files".

‚Ä¢ **Evitar Over-partitioning:** Deve-se particionar os dados (por exemplo, por data ou neg√≥cio) apenas quando houver volume suficiente para justificar a divis√£o. Particionar dados de baixo volume por granularidades muito finas (como minutos ou IDs √∫nicos) gera milhares de pastas com arquivos min√∫sculos.

‚Ä¢ **Pruning:** O particionamento correto permite o **partition pruning** (poda de parti√ß√£o), onde o motor de busca ignora parti√ß√µes desnecess√°rias, reduzindo drasticamente o I/O e o custo por consulta, desde que os arquivos dentro das parti√ß√µes tenham o tamanho ideal


**3.Glue Workflow**

- Usar para pipelines ETL e Glue e athena com uma simplicidade maior

**4.Data Viz**

- Bolha para 3 vari√°veis e dispers√£o para 2.  

# 1Ô∏è‚É£ Modelagem **OLTP** (Transacional)

### üéØ Objetivo

- Muitas escritas
    
- Baixa lat√™ncia
    
- Consist√™ncia
- ## üõ† Servi√ßos AWS

- **Amazon RDS** (Postgres, MySQL, SQL Server)
    
- **Aurora**
# 2Ô∏è‚É£ Modelagem **OLAP** (Analytics / BI)

### üéØ Objetivo

- Leitura pesada
    
- Agrega√ß√µes
    
- Hist√≥rico
- ## üõ† Servi√ßos AWS

- **Athena**
    
- **Redshift**
    
- **Glue Catalog**
    
- **S3 (Data Lake)**
Enunciado: Considere duas tabelas, 'transacoes' e 'clientes'. A tabela 'transacoes' cont√©m informa√ß√µes sobre as transa√ß√µes financeiras dos clientes, e a tabela 'clientes' cont√©m informa√ß√µes de clientes. 

Preencha as lacunas da consulta ao lado que calcula a *quantidade total de transa√ß√µes por cliente* e o *valor total de transa√ß√µes por cliente*, por√©m o c√°lculo precisa ser feito apenas os clientes que realizaram mais de 5 transa√ß√µes. A consulta precisa trazer o id do cliente, seu nome e os valores requeridos. Assuma que h√° um id √∫nico para cada cliente √∫nico id para as transa√ß√µes.
Preencha as lacunas na consulta ao lado:
#### Tabelas:
‚Ä¢*sql
-- Tabela transacoes
CREATE TABLE transacoes (
id INT, 
cliente id INT, 
valor DECIMAL (10, 2), 
data DATE
-- Tabela clientes
CREATE TABLE clientes
id INT, 
nome VARCHAR(100)
); 


select 
c.id,
c.nome,
count(t.id) as qtd_transacoes_clients,
sum(t.valor) as total_transacoes_clients
from 
clientes c 
join transacoes t on t.cliente_id = c.id
group by 
c.id, 
c.nome
having count(t.id) > 5 

Transa√ß√µes ACID s√£o um¬†conjunto de propriedades (Atomicidade, Consist√™ncia, Isolamento, Durabilidade) que garantem a fiabilidade, integridade e consist√™ncia dos dados em sistemas de banco de dados, especialmente durante falhas 

‚Ä¢ **ETL na AWS:** S3 com dados brutos, Glue Job para transforma√ß√£o das camadas, athena para leitura 

‚Ä¢ **ELT na AWS:**  S3 com dados brutos, como load Crawler ou Athena direto no S3 e transforma√ß√£o no Athena.

| Feature    | DynamicFrame (AWS Glue specific)                   | PySpark DataFrame (Apache Spark native) |
| ---------- | -------------------------------------------------- | --------------------------------------- |
| **Schema** | Flexible, schema-on-read, handles inconsistencies. | Requires a fixed, set schema.           |

|Tipo|Estrutura|Exemplos|
|---|---|---|
|Estruturado|Schema fixo|SQL, CSV, Excel, Parquet|
|Semi-estruturado|Schema flex√≠vel|JSON, YAML, logs|
|N√£o estruturado|Sem schema|Imagem, v√≠deo, PDF|
